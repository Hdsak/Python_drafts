{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.12541308,  1.96429418],\n       [-1.15329466, -0.50068741],\n       [ 0.29529406, -0.22809346],\n       [ 0.57385917, -0.42335076],\n       [ 1.40955451, -0.81216255]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 20.1 Preprocessing Data for Neural Networks\n",
    "\n",
    "# Load libraries\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Create feature\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "[-200.2, -234.1],\n",
    "\n",
    "[5000.5, 150.1],\n",
    "[6000.6, -125.1],\n",
    "[9000.9, -673.1]])\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Transform the feature\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "# Show feature\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#20.2 Designing a Neural Network\n",
    "# Load libraries\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Dense(16, activation = \"relu\", input_shape = (10,)))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.4971 - val_loss: 0.6961 - val_accuracy: 0.4780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5355 - val_loss: 0.6974 - val_accuracy: 0.4847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5696 - val_loss: 0.7138 - val_accuracy: 0.4676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 20.3 Training a Binary Classifier\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\n",
    "number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "history = network.fit(\n",
    "    features_train,\n",
    "    target_test,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    batch_size=100,\n",
    "    validation_data=(features_test,target_test)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 20.4 Training a Multiclass Classifier\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 5000\n",
    "# Load feature and target data\n",
    "data = reuters.load_data(num_words=number_of_features)\n",
    "(data_train, target_vector_train), (data_test, target_vector_test) = data\n",
    "# Convert feature data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# One-hot encode target vector to create a target matrix\n",
    "target_train = to_categorical(target_vector_train)\n",
    "target_test = to_categorical(target_vector_test)\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100, activation=\"relu\"))\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units=46, activation=\"softmax\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target\n",
    "epochs=3, # Three epochs\n",
    "verbose=0, # No output\n",
    "batch_size=100, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "# 20.5 Training a Regressor\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "n_features = 3,\n",
    "n_informative = 3,\n",
    "n_targets = 1,\n",
    "noise = 0.0,\n",
    "random_state = 0)\n",
    "# Divide our data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.33, random_state=0)\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32,\n",
    "activation=\"relu\",\n",
    "input_shape=(features_train.shape[1],)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32, activation=\"relu\"))\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"mse\", # Mean squared error\n",
    "optimizer=\"RMSprop\", # Optimization algorithm\n",
    "metrics=[\"mse\"]) # Mean squared error\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target vector\n",
    "epochs=10, # Number of epochs\n",
    "verbose=0, # No output\n",
    "batch_size=100, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 20.6 Making Predictions\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 10000\n",
    "# Load data and target vector from IMDB movie data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "# Convert IMDB data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target vector\n",
    "epochs=3, # Number of epochs\n",
    "verbose=0, # No output\n",
    "batch_size=100, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data\n",
    "# Predict classes of test set\n",
    "predicted_target = network.predict(features_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20.7 Visualize Training History\n",
    "import matplotlib.pyplot as plt\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 10000\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target\n",
    "epochs=15, # Number of epochs\n",
    "verbose=0, # No output\n",
    "batch_size=1000, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history[\"loss\"]\n",
    "test_loss = history.history[\"val_loss\"]\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-fc931c24eb6f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Get training and test accuracy histories\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtraining_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"acc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mtest_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"val_acc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining_accuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"r--\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_accuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"b-\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history[\"acc\"]\n",
    "test_accuracy = history.history[\"val_acc\"]\n",
    "plt.plot(epoch_count, training_accuracy, \"r--\")\n",
    "plt.plot(epoch_count, test_accuracy, \"b-\")\n",
    "# Visualize accuracy history\n",
    "plt.legend([\"Training Accuracy\", \"Test Accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "# 20.8 Reducing Overfitting with Weight Regularization\n",
    "\n",
    "from keras import regularizers\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "kernel_regularizer=regularizers.l2(0.01),\n",
    "input_shape=(number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "kernel_regularizer=regularizers.l2(0.01),\n",
    "activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target vector\n",
    "epochs=3, # Number of epochs\n",
    "verbose=0, # No output\n",
    "batch_size=100, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "c:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 20.9 Reducing Overfitting with Early Stopping\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "number_of_features = 1000\n",
    "\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode = 'binary')\n",
    "features_test = tokenizer.sequences_to_matrix(data_train, mode = 'binary')\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16,\n",
    "                       activation='relu',\n",
    "                       input_shape=(number_of_features,)))\n",
    "model.add(layers.Dense(\n",
    "    16,\n",
    "    activation='relu'\n",
    "))\n",
    "model.add(layers.Dense(\n",
    "    1,\n",
    "    activation='sigmoid'\n",
    "))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callback = [EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2),ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs = 20,\n",
    "    callbacks = callback,\n",
    "    verbose = 0,\n",
    "    batch_size= 100,\n",
    "    validation_data= (features_test, target_test)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# 20.10 Reducing Overfitting with Dropout\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "number_of_features = 1000\n",
    "\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(num_words= number_of_features)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode='binary')\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode = 'binary')\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dropout(0.2, input_shape = (number_of_features,)))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "# Add a dropout layer for previous hidden layer\n",
    "model.add(layers.Dropout(0.5))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "model.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add a dropout layer for previous hidden layer\n",
    "model.add(layers.Dropout(0.5))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs = 3,\n",
    "    verbose= 0,\n",
    "    validation_data = (features_test, target_test),\n",
    "    batch_size = 100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 20.11 Saving Model Training Progress\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "activation=\"relu\",\n",
    "input_shape=(number_of_features,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath=\"models.hdf5\")]\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target vector\n",
    "epochs=3, # Number of epochs\n",
    "callbacks=checkpoint, # Checkpoint\n",
    "verbose=0, # No output\n",
    "batch_size=100, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.90011996, 0.91149116, 0.89378935])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20.12 k-Fold Cross-Validating Neural Networks\n",
    "\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Number of features\n",
    "number_of_features = 100\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "    n_features = number_of_features,\n",
    "    n_informative = 3,\n",
    "    n_redundant = 0,\n",
    "    n_classes = 2,\n",
    "    weights = [.5, .5],\n",
    "    random_state = 0)\n",
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\n",
    "    number_of_features,)))\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "    optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "    # Return compiled network\n",
    "    return network\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "nn = KerasClassifier(\n",
    "    build_fn = create_network,\n",
    "    epochs = 10,\n",
    "    batch_size = 100,\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "cross_val_score(nn, features, target, cv= 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 20.13 Tuning Neural Networks\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Number of features\n",
    "number_of_features = 100\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "n_features = number_of_features,\n",
    "n_informative = 3,\n",
    "n_redundant = 0,\n",
    "n_classes = 2,\n",
    "weights = [.5, .5],\n",
    "random_state = 0)\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "# Create function returning a compiled network\n",
    "def create_network(optimizer=\"rmsprop\"):\n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16,\n",
    "    activation=\"relu\",\n",
    "    input_shape=(number_of_features,)))\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "    optimizer=optimizer, # Optimizer\n",
    "    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "    # Return compiled network\n",
    "    return network\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0)\n",
    "# Create hyperparameter space\n",
    "epochs = [5, 10]\n",
    "batches = [5, 10, 100]\n",
    "optimizers = [\"rmsprop\", \"adam\"]\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(features, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-ec53bc653bb1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[0mnetwork\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"sigmoid\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# Visualize network architecture\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0mSVG\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_to_dot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshow_shapes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprog\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"dot\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"svg\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "# 20.14 Visualizing Neural Networks\n",
    "\n",
    "# Load libraries\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(10,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Visualize network architecture\n",
    "SVG(model_to_dot(network, show_shapes=True).create(prog=\"dot\", format=\"svg\"))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential_78/max_pooling2d_5/MaxPool (defined at <ipython-input-18-969331876627>:54) ]] [Op:__inference_train_function_862049]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-969331876627>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     52\u001B[0m metrics=[\"accuracy\"]) # Accuracy performance metric\n\u001B[0;32m     53\u001B[0m \u001B[1;31m# Train neural network\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m network.fit(features_train,\n\u001B[0m\u001B[0;32m     55\u001B[0m \u001B[0mtarget_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[0;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1098\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1099\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    839\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 840\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    841\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m       \u001B[0mcanon_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcanon_kwds\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2829\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2831\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1841\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m     \"\"\"\n\u001B[1;32m-> 1843\u001B[1;33m     return self._call_flat(\n\u001B[0m\u001B[0;32m   1844\u001B[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[0;32m   1845\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1921\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1922\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1923\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1924\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    546\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential_78/max_pooling2d_5/MaxPool (defined at <ipython-input-18-969331876627>:54) ]] [Op:__inference_train_function_862049]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Classiefying\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)\n",
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)\n",
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n",
    "# Start neural network\n",
    "network = Sequential()\n",
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation\n",
    "\n",
    "network.add(Conv2D(filters=64,\n",
    "kernel_size=(5, 5),\n",
    "input_shape=(channels, width, height),\n",
    "activation='relu'))\n",
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D())\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "# Add layer to flatten input\n",
    "network.add(Flatten())\n",
    "# # Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(128, activation=\"relu\"))\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "network.fit(features_train,\n",
    "target_train,\n",
    "epochs=2,\n",
    "verbose=0,\n",
    "batch_size=1000,\n",
    "validation_data=(features_test, target_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'raw/images'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-d21be63b0701>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m rotation_range=90) # Randomly rotate\n\u001B[0;32m     11\u001B[0m \u001B[1;31m# Process all images from the directory 'raw/images'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m augment_images = augmentation.flow_from_directory(\"raw/images\", # Image folder\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;31m# Batch size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mclass_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"binary\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;31m# Classes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001B[0m in \u001B[0;36mflow_from_directory\u001B[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001B[0m\n\u001B[0;32m    941\u001B[0m             \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0my\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0marray\u001B[0m \u001B[0mof\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    942\u001B[0m     \"\"\"\n\u001B[1;32m--> 943\u001B[1;33m     return DirectoryIterator(\n\u001B[0m\u001B[0;32m    944\u001B[0m         \u001B[0mdirectory\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    945\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloatx\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m       \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'dtype'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m     super(DirectoryIterator, self).__init__(\n\u001B[0m\u001B[0;32m    382\u001B[0m         \u001B[0mdirectory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage_data_generator\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[0mtarget_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtarget_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[0;32m    113\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mclasses\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m             \u001B[0mclasses\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 115\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0msubdir\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msorted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    116\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubdir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m                     \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubdir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Системе не удается найти указанный путь: 'raw/images'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 20.16 Improving Performance with Image Augmentation\n",
    "\n",
    "# Load library\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Create image augmentation\n",
    "augmentation = ImageDataGenerator(featurewise_center=True, # Apply ZCA whitening\n",
    "zoom_range=0.3, # Randomly zoom in on images\n",
    "width_shift_range=0.2, # Randomly shift images\n",
    "horizontal_flip=True, # Randomly flip images\n",
    "rotation_range=90) # Randomly rotate\n",
    "# Process all images from the directory 'raw/images'\n",
    "augment_images = augmentation.flow_from_directory('need path', # Image folder\n",
    "batch_size=32, # Batch size\n",
    "class_mode=\"binary\", # Classes\n",
    "save_to_dir=\"processed/images\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1811\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1812\u001B[1;33m     \u001B[0mc_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpywrap_tf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_FinishOperation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_desc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1813\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-20-1a8b8aa731fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[0mnetwork\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEmbedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnumber_of_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;31m# Add a long short-term memory layer with 128 units\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[0mnetwork\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;31m# Add fully connected layer with a sigmoid activation function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[0mnetwork\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"sigmoid\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    455\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 457\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    458\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36madd\u001B[1;34m(self, layer)\u001B[0m\n\u001B[0;32m    219\u001B[0m       \u001B[1;31m# If the model is being built continuously on top of an input layer:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m       \u001B[1;31m# refresh its output.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 221\u001B[1;33m       \u001B[0moutput_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    222\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mRNN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    661\u001B[0m     \u001B[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    923\u001B[0m     \u001B[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    924\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 925\u001B[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0m\u001B[0;32m    926\u001B[0m                                                 input_list)\n\u001B[0;32m    927\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[1;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[0;32m   1115\u001B[0m           \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1116\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1117\u001B[1;33m               \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcast_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1119\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOperatorNotAllowedInGraphError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[0;32m   1181\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m         (last_output, outputs, new_h, new_c,\n\u001B[1;32m-> 1183\u001B[1;33m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001B[0m\u001B[0;32m   1184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1185\u001B[0m       \u001B[0mstates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mnew_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_c\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mlstm_with_backend_selection\u001B[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001B[0m\n\u001B[0;32m   1555\u001B[0m   \u001B[1;31m# Call the normal LSTM impl and register the CuDNN impl function. The\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1556\u001B[0m   \u001B[1;31m# grappler will kick in during session execution to optimize the graph.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1557\u001B[1;33m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001B[0m\u001B[0;32m   1558\u001B[0m       **params)\n\u001B[0;32m   1559\u001B[0m   \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdefun_gpu_lstm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2826\u001B[0m     \u001B[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2828\u001B[1;33m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2829\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3213\u001B[1;33m       \u001B[0mgraph_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3214\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3215\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3063\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3064\u001B[0m     graph_function = ConcreteFunction(\n\u001B[1;32m-> 3065\u001B[1;33m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[0;32m   3066\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3067\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    985\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 986\u001B[1;33m       \u001B[0mfunc_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    987\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    988\u001B[0m       \u001B[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mstandard_lstm\u001B[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001B[0m\n\u001B[0;32m   1303\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1304\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1305\u001B[1;33m   last_output, outputs, new_states = K.rnn(\n\u001B[0m\u001B[0;32m   1306\u001B[0m       \u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1307\u001B[0m       \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0minit_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_c\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36mrnn\u001B[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001B[0m\n\u001B[0;32m   4211\u001B[0m     \u001B[1;31m# output_time_zero is used to determine the cell output shape and its dtype.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4212\u001B[0m     \u001B[1;31m# the value is discarded.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4213\u001B[1;33m     output_time_zero, _ = step_function(\n\u001B[0m\u001B[0;32m   4214\u001B[0m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001B[0;32m   4215\u001B[0m     output_ta = tuple(\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(cell_inputs, cell_states)\u001B[0m\n\u001B[0;32m   1291\u001B[0m     \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcell_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1292\u001B[0m     \u001B[0mz\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh_tm1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecurrent_kernel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1293\u001B[1;33m     \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1294\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1295\u001B[0m     \u001B[0mz0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mz3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36mbias_add\u001B[1;34m(x, bias, data_format)\u001B[0m\n\u001B[0;32m   5770\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbias_shape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5771\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mdata_format\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'channels_first'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5772\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_format\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'NCHW'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5773\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_format\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'NHWC'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5774\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mndim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mbias_add\u001B[1;34m(value, bias, data_format, name)\u001B[0m\n\u001B[0;32m   3363\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3364\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3365\u001B[1;33m       return gen_nn_ops.bias_add(\n\u001B[0m\u001B[0;32m   3366\u001B[0m           value, bias, data_format=data_format, name=name)\n\u001B[0;32m   3367\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001B[0m in \u001B[0;36mbias_add\u001B[1;34m(value, bias, data_format, name)\u001B[0m\n\u001B[0;32m    691\u001B[0m     \u001B[0mdata_format\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"NHWC\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    692\u001B[0m   \u001B[0mdata_format\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_execute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_format\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"data_format\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 693\u001B[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001B[0m\u001B[0;32m    694\u001B[0m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001B[0;32m    695\u001B[0m   \u001B[0m_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[1;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    740\u001B[0m       \u001B[1;31m# Add Op to graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    741\u001B[0m       \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 742\u001B[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001B[0m\u001B[0;32m    743\u001B[0m                                  \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscope\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    744\u001B[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m    589\u001B[0m       \u001B[0minp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcapture\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    590\u001B[0m       \u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    592\u001B[0m         \u001B[0mop_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m         compute_device)\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m   3475\u001B[0m     \u001B[1;31m# Session.run call cannot occur between creating and mutating the op.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3476\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mutation_lock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3477\u001B[1;33m       ret = Operation(\n\u001B[0m\u001B[0;32m   3478\u001B[0m           \u001B[0mnode_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3479\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001B[0m\n\u001B[0;32m   1972\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mop_def\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1973\u001B[0m         \u001B[0mop_def\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_graph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_op_def\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1974\u001B[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001B[0m\u001B[0;32m   1975\u001B[0m                                 control_input_ops, op_def)\n\u001B[0;32m   1976\u001B[0m       \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hdsak\\pycharmprojects\\chris_albon_ml_to_deep\\new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1813\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1814\u001B[0m     \u001B[1;31m# Convert to ValueError for backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1815\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1816\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1817\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mc_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512]."
     ]
    }
   ],
   "source": [
    "\n",
    "# 20.17 Classifying Text\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import models\n",
    "from keras import layers\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "num_words=number_of_features)\n",
    "# Use padding or truncation to make each observation have 400 features\n",
    "features_train = sequence.pad_sequences(data_train, maxlen=400)\n",
    "features_test = sequence.pad_sequences(data_test, maxlen=400)\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "# Add an embedding layer\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n",
    "# Add a long short-term memory layer with 128 units\n",
    "network.add(layers.LSTM(units=128))\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "optimizer=\"Adam\", # Adam optimization\n",
    "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "target_train, # Target\n",
    "epochs=3, # Number of epochs\n",
    "verbose=0, # Do not print description after each epoch\n",
    "batch_size=1000, # Number of observations per batch\n",
    "validation_data=(features_test, target_test)) # Test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}