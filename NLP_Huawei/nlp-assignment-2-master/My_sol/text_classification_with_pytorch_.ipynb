{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "text-classification-with-pytorch .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Data Reading"
      ],
      "metadata": {
        "id": "DbVESLdCyr5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "\n",
        "import spacy # I'll be making use of spacy for text preprocessing\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "import string, re\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "from matplotlib.pyplot import plot, hist, xlabel, legend\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt='%H:%M:%S', level=logging.INFO)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-03-29T12:52:04.707846Z",
          "iopub.execute_input": "2022-03-29T12:52:04.708483Z",
          "iopub.status.idle": "2022-03-29T12:52:04.727868Z",
          "shell.execute_reply.started": "2022-03-29T12:52:04.708208Z",
          "shell.execute_reply": "2022-03-29T12:52:04.727179Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k3qEvYXvyr5k",
        "outputId": "b769fa87-d846-4a8b-ce57-c5a239c07658"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/dataset/train.csv')\n",
        "test = pd.read_csv('/content/dataset/test.csv')\n",
        "sub = pd.read_csv('/content/dataset/submission.csv')\n",
        "\n",
        "train.drop_duplicates(subset=['comment_text'], inplace=True)\n",
        "print('Training Set Shape = {}'.format(train.shape))\n",
        "print('Training Set Memory Usage = {:.2f} MB'.format(train.memory_usage().sum() / 1024**2))\n",
        "print('Test Set Shape = {}'.format(test.shape))\n",
        "print('Test Set Memory Usage = {:.2f} MB'.format(test.memory_usage().sum() / 1024**2))\n",
        "print('\\n\\tFirst five rows of our data:\\n')\n",
        "print(train.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:53:14.014748Z",
          "iopub.execute_input": "2022-03-29T12:53:14.015052Z",
          "iopub.status.idle": "2022-03-29T12:53:14.210389Z",
          "shell.execute_reply.started": "2022-03-29T12:53:14.014999Z",
          "shell.execute_reply": "2022-03-29T12:53:14.209103Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcC78dBVyr5n",
        "outputId": "a4a60453-8239-4960-c7dd-8b237dcc5a9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape = (34581, 3)\n",
            "Training Set Memory Usage = 1.06 MB\n",
            "Test Set Shape = (9194, 2)\n",
            "Test Set Memory Usage = 0.14 MB\n",
            "\n",
            "\tFirst five rows of our data:\n",
            "\n",
            "   id                                       comment_text  toxicity\n",
            "0   0                 fuck you you self righteous creep          3\n",
            "1   1   stop stop the goddam vandalism or there ll be...         2\n",
            "2   2  i agree rt does have a few shortcomings  but i...         0\n",
            "3   3  if you would like verfiability here is the lin...         0\n",
            "4   4  do you think there s consensus for me to be on...         0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values"
      ],
      "metadata": {
        "id": "Wtf3Ehblyr5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.dropna()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:53:46.265104Z",
          "iopub.execute_input": "2022-03-29T12:53:46.265432Z",
          "iopub.status.idle": "2022-03-29T12:53:46.281710Z",
          "shell.execute_reply.started": "2022-03-29T12:53:46.265380Z",
          "shell.execute_reply": "2022-03-29T12:53:46.280711Z"
        },
        "trusted": true,
        "id": "9jQ3_xeEyr5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.rename(columns={\"comment_text\": \"text\", \"toxicity\": \"target\"})\n",
        "test = test.rename(columns={\"comment_text\": \"text\"})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:57:13.849977Z",
          "iopub.execute_input": "2022-03-29T12:57:13.850299Z",
          "iopub.status.idle": "2022-03-29T12:57:13.859805Z",
          "shell.execute_reply.started": "2022-03-29T12:57:13.850242Z",
          "shell.execute_reply": "2022-03-29T12:57:13.859067Z"
        },
        "trusted": true,
        "id": "OSl9MWdPyr5s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:57:19.399235Z",
          "iopub.execute_input": "2022-03-29T12:57:19.399671Z",
          "iopub.status.idle": "2022-03-29T12:57:19.411339Z",
          "shell.execute_reply.started": "2022-03-29T12:57:19.399629Z",
          "shell.execute_reply": "2022-03-29T12:57:19.410334Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CxB3hmAeyr5u",
        "outputId": "e554bfc6-a2b6-4fb7-b8e8-f5c3c574f2e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                               text\n",
              "0     34647  oh that great repository of free cultural work...\n",
              "1     34648  my rfa  with apologies for the impersonal awb ...\n",
              "2     34649  it looks like a number of articles you created...\n",
              "3     34650  oh  but i see you ve been  block  for other  s...\n",
              "4     34651  accord of the discussion in mariah carey compo...\n",
              "...     ...                                                ...\n",
              "9189  43836  atat  rk you cannot escape atat  rk s racial s...\n",
              "9190  43837  irresponsible dumheads  each and every image h...\n",
              "9191  43838  i agrre with above and i checked and in shia s...\n",
              "9192  43839  i think there should be some form of screening...\n",
              "9193  43840                      i  suck ed as an admin anyway\n",
              "\n",
              "[9194 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4fdae3f-d5f2-470e-8563-f93c0e679054\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34647</td>\n",
              "      <td>oh that great repository of free cultural work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34648</td>\n",
              "      <td>my rfa  with apologies for the impersonal awb ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34649</td>\n",
              "      <td>it looks like a number of articles you created...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34650</td>\n",
              "      <td>oh  but i see you ve been  block  for other  s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34651</td>\n",
              "      <td>accord of the discussion in mariah carey compo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9189</th>\n",
              "      <td>43836</td>\n",
              "      <td>atat  rk you cannot escape atat  rk s racial s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9190</th>\n",
              "      <td>43837</td>\n",
              "      <td>irresponsible dumheads  each and every image h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9191</th>\n",
              "      <td>43838</td>\n",
              "      <td>i agrre with above and i checked and in shia s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9192</th>\n",
              "      <td>43839</td>\n",
              "      <td>i think there should be some form of screening...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9193</th>\n",
              "      <td>43840</td>\n",
              "      <td>i  suck ed as an admin anyway</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9194 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4fdae3f-d5f2-470e-8563-f93c0e679054')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4fdae3f-d5f2-470e-8563-f93c0e679054 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4fdae3f-d5f2-470e-8563-f93c0e679054');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building "
      ],
      "metadata": {
        "id": "zrrm9RK7yr5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train['text']\n",
        "df_test = test['text']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:57:45.547287Z",
          "iopub.execute_input": "2022-03-29T12:57:45.547869Z",
          "iopub.status.idle": "2022-03-29T12:57:45.552709Z",
          "shell.execute_reply.started": "2022-03-29T12:57:45.547802Z",
          "shell.execute_reply": "2022-03-29T12:57:45.551998Z"
        },
        "trusted": true,
        "id": "PpIZVMSkyr5v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing with spacy\n",
        "\n",
        "def clean_text(text):\n",
        "    return text.strip().lower()\n",
        "\n",
        "punctuations = string.punctuation\n",
        "nlp = spacy.load('en')\n",
        "stop_words = STOP_WORDS\n",
        "parser = English()\n",
        "\n",
        "def spacy_preprocessor(sentence):\n",
        "    \"\"\"Tokenize, Lemmatize, Remove Stopwords\"\"\"\n",
        "    mytokens = parser(sentence)\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "    result = ' '.join(mytokens)\n",
        "    return result\n",
        "\n",
        "df_train = df_train.apply(lambda x: spacy_preprocessor(x))\n",
        "df_test = df_test.apply(lambda x: spacy_preprocessor(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:57:50.832467Z",
          "iopub.execute_input": "2022-03-29T12:57:50.833083Z",
          "iopub.status.idle": "2022-03-29T12:58:13.950873Z",
          "shell.execute_reply.started": "2022-03-29T12:57:50.833019Z",
          "shell.execute_reply": "2022-03-29T12:58:13.949681Z"
        },
        "trusted": true,
        "id": "AUEFpYcwyr5w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = df_train\n",
        "test['text'] = df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:58:25.662160Z",
          "iopub.execute_input": "2022-03-29T12:58:25.662771Z",
          "iopub.status.idle": "2022-03-29T12:58:25.671221Z",
          "shell.execute_reply.started": "2022-03-29T12:58:25.662419Z",
          "shell.execute_reply": "2022-03-29T12:58:25.670514Z"
        },
        "trusted": true,
        "id": "SeDk3riPyr5w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train[[col for col in train.columns if not col == 'target']]\n",
        "y = train['target']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "valid_data = pd.concat([X_valid, y_valid], axis=1)\n",
        "\n",
        "# save them\n",
        "!mkdir preprocessed_data\n",
        "train_data.to_csv('preprocessed_data/train.csv', index=False)\n",
        "valid_data.to_csv('preprocessed_data/valid.csv', index=False)\n",
        "test.to_csv('preprocessed_data/test.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T12:58:27.417460Z",
          "iopub.execute_input": "2022-03-29T12:58:27.417808Z",
          "iopub.status.idle": "2022-03-29T12:58:28.571855Z",
          "shell.execute_reply.started": "2022-03-29T12:58:27.417751Z",
          "shell.execute_reply": "2022-03-29T12:58:28.570857Z"
        },
        "trusted": true,
        "id": "FrqClyRiyr5x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "print(f\"Cuda Status on the system is {is_cuda}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:16.357744Z",
          "iopub.execute_input": "2022-03-29T13:02:16.358069Z",
          "iopub.status.idle": "2022-03-29T13:02:16.363192Z",
          "shell.execute_reply.started": "2022-03-29T13:02:16.358012Z",
          "shell.execute_reply": "2022-03-29T13:02:16.362427Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rioSse-yr5y",
        "outputId": "6fdb2f73-5579-4c62-d20a-6d03a45159de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda Status on the system is True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a fixed length to process the string\n",
        "fix_length = 17\n",
        "text = data.Field(tokenize=\"spacy\",\n",
        "                  pad_first=True)\n",
        "\n",
        "# define train, validation and test sets\n",
        "train_data = data.TabularDataset(path=\"preprocessed_data/train.csv\",\n",
        "                                 format=\"csv\",\n",
        "                                 fields=[\n",
        "                                         ('id', data.Field()),\n",
        "                                         ('text', text),\n",
        "                                         ('target', data.Field())],\n",
        "                                 skip_header=True)\n",
        "\n",
        "valid_data = data.TabularDataset(path=\"preprocessed_data/valid.csv\",\n",
        "                                 format=\"csv\",\n",
        "                                 fields=[\n",
        "                                         ('id', data.Field()),\n",
        "                                         ('text', text),\n",
        "                                         ('target', data.Field())],\n",
        "                                 skip_header=True)\n",
        "\n",
        "test_data = data.TabularDataset(path=\"preprocessed_data/test.csv\",\n",
        "                                format=\"csv\",\n",
        "                                fields=[\n",
        "                                        ('id', data.Field()),\n",
        "                                        ('text', text),\n",
        "                                        ],\n",
        "                                skip_header=True)\n",
        "\n",
        "text.build_vocab(train_data, valid_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:16.541138Z",
          "iopub.execute_input": "2022-03-29T13:02:16.541472Z",
          "iopub.status.idle": "2022-03-29T13:02:32.702257Z",
          "shell.execute_reply.started": "2022-03-29T13:02:16.541411Z",
          "shell.execute_reply": "2022-03-29T13:02:32.701240Z"
        },
        "trusted": true,
        "id": "ZS-zY663yr5y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(text.vocab)\n",
        "NGRAMS = 2\n",
        "BATCH_SIZE = 8\n",
        "EMBED_DIM = 32\n",
        "NUM_CLASS = 6"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.704677Z",
          "iopub.execute_input": "2022-03-29T13:02:32.705060Z",
          "iopub.status.idle": "2022-03-29T13:02:32.710332Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.704984Z",
          "shell.execute_reply": "2022-03-29T13:02:32.709314Z"
        },
        "trusted": true,
        "id": "YIuZz9Jtyr5z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        # initialize the weights\n",
        "        self.init_weights()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.711983Z",
          "iopub.execute_input": "2022-03-29T13:02:32.712455Z",
          "iopub.status.idle": "2022-03-29T13:02:32.726128Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.712402Z",
          "shell.execute_reply": "2022-03-29T13:02:32.725335Z"
        },
        "trusted": true,
        "id": "6oYZRTgbyr5z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUM_CLASS).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.727703Z",
          "iopub.execute_input": "2022-03-29T13:02:32.728078Z",
          "iopub.status.idle": "2022-03-29T13:02:32.779715Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.728021Z",
          "shell.execute_reply": "2022-03-29T13:02:32.778479Z"
        },
        "trusted": true,
        "id": "BLTt1d6Fyr50"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(batch):\n",
        "    label = torch.tensor([int(entry.target[0]) for entry in batch])\n",
        "    _text = []\n",
        "    for entry in batch:\n",
        "        _entry = []\n",
        "        for t in entry.text:\n",
        "            _entry.append(text.vocab.stoi[t])\n",
        "        _text.append(torch.tensor(_entry,dtype=torch.long))\n",
        "    offsets = [0] + [len(entry) for entry in _text]\n",
        "    # torch.Tensor.cumsum returns the cumulative sum\n",
        "    # of elements in the dimension dim.\n",
        "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    _text = torch.cat(_text)\n",
        "    return _text, offsets, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.782772Z",
          "iopub.execute_input": "2022-03-29T13:02:32.783160Z",
          "iopub.status.idle": "2022-03-29T13:02:32.791079Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.783088Z",
          "shell.execute_reply": "2022-03-29T13:02:32.790024Z"
        },
        "trusted": true,
        "id": "Zi_aSDoIyr50"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_func(sub_train_):\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.792892Z",
          "iopub.execute_input": "2022-03-29T13:02:32.793423Z",
          "iopub.status.idle": "2022-03-29T13:02:32.810818Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.793371Z",
          "shell.execute_reply": "2022-03-29T13:02:32.809604Z"
        },
        "trusted": true,
        "id": "vLMvdDQQyr51"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_data) * 0.95)\n",
        "sub_train_, sub_valid_ = random_split(train_data, [train_len, len(train_data) - train_len])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "    \n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "    \n",
        "    print(f'Epoch: {epoch + 1}, | time in {mins} minutes and {secs} seconds')\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:02:32.812416Z",
          "iopub.execute_input": "2022-03-29T13:02:32.812991Z",
          "iopub.status.idle": "2022-03-29T13:04:09.431769Z",
          "shell.execute_reply.started": "2022-03-29T13:02:32.812936Z",
          "shell.execute_reply": "2022-03-29T13:04:09.430742Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjRLbP5-yr52",
        "outputId": "181e951a-18d1-492d-bcad-faf194964f6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.1280(train)\t|\tAcc: 59.7%(train)\n",
            "\tLoss: 0.0013(valid)\t|\tAcc: 63.3%(valid)\n",
            "Epoch: 2, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.1090(train)\t|\tAcc: 65.6%(train)\n",
            "\tLoss: 0.0010(valid)\t|\tAcc: 64.7%(valid)\n",
            "Epoch: 3, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.1002(train)\t|\tAcc: 68.6%(train)\n",
            "\tLoss: 0.0010(valid)\t|\tAcc: 63.8%(valid)\n",
            "Epoch: 4, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0931(train)\t|\tAcc: 71.1%(train)\n",
            "\tLoss: 0.0013(valid)\t|\tAcc: 61.8%(valid)\n",
            "Epoch: 5, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0868(train)\t|\tAcc: 73.4%(train)\n",
            "\tLoss: 0.0012(valid)\t|\tAcc: 63.9%(valid)\n",
            "Epoch: 6, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0815(train)\t|\tAcc: 75.9%(train)\n",
            "\tLoss: 0.0011(valid)\t|\tAcc: 63.7%(valid)\n",
            "Epoch: 7, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0764(train)\t|\tAcc: 77.6%(train)\n",
            "\tLoss: 0.0009(valid)\t|\tAcc: 62.9%(valid)\n",
            "Epoch: 8, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0716(train)\t|\tAcc: 79.3%(train)\n",
            "\tLoss: 0.0015(valid)\t|\tAcc: 62.0%(valid)\n",
            "Epoch: 9, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0674(train)\t|\tAcc: 80.7%(train)\n",
            "\tLoss: 0.0012(valid)\t|\tAcc: 62.4%(valid)\n",
            "Epoch: 10, | time in 0.1 minutes and 6 seconds\n",
            "\tLoss: 0.0634(train)\t|\tAcc: 82.4%(train)\n",
            "\tLoss: 0.0008(valid)\t|\tAcc: 64.0%(valid)\n",
            "Epoch: 11, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0600(train)\t|\tAcc: 83.5%(train)\n",
            "\tLoss: 0.0006(valid)\t|\tAcc: 61.8%(valid)\n",
            "Epoch: 12, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0567(train)\t|\tAcc: 84.6%(train)\n",
            "\tLoss: 0.0006(valid)\t|\tAcc: 61.2%(valid)\n",
            "Epoch: 13, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0540(train)\t|\tAcc: 85.6%(train)\n",
            "\tLoss: 0.0012(valid)\t|\tAcc: 61.8%(valid)\n",
            "Epoch: 14, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0509(train)\t|\tAcc: 86.7%(train)\n",
            "\tLoss: 0.0008(valid)\t|\tAcc: 61.3%(valid)\n",
            "Epoch: 15, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0491(train)\t|\tAcc: 87.3%(train)\n",
            "\tLoss: 0.0010(valid)\t|\tAcc: 60.8%(valid)\n",
            "Epoch: 16, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0465(train)\t|\tAcc: 88.2%(train)\n",
            "\tLoss: 0.0012(valid)\t|\tAcc: 60.0%(valid)\n",
            "Epoch: 17, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0445(train)\t|\tAcc: 88.7%(train)\n",
            "\tLoss: 0.0011(valid)\t|\tAcc: 60.7%(valid)\n",
            "Epoch: 18, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0428(train)\t|\tAcc: 89.3%(train)\n",
            "\tLoss: 0.0010(valid)\t|\tAcc: 60.3%(valid)\n",
            "Epoch: 19, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0412(train)\t|\tAcc: 89.8%(train)\n",
            "\tLoss: 0.0009(valid)\t|\tAcc: 60.7%(valid)\n",
            "Epoch: 20, | time in 0.08333333333333333 minutes and 5 seconds\n",
            "\tLoss: 0.0398(train)\t|\tAcc: 90.2%(train)\n",
            "\tLoss: 0.0007(valid)\t|\tAcc: 61.0%(valid)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(_text, model, vocab, ngrams):\n",
        "    if len(_text) == 0:\n",
        "        return 0\n",
        "    with torch.no_grad():\n",
        "        _text = [vocab.stoi[token] for token in ngrams_iterator(_text, ngrams)]\n",
        "        output = model(torch.tensor(_text), torch.tensor([0]))\n",
        "        return output.argmax(1).item()\n",
        "\n",
        "model = model.to('cpu')\n",
        "predictions = [predict(entry.text, model, text.vocab, NGRAMS) for entry in test_data]\n",
        "tweet_id = [entry.id[0] for entry in test_data]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:06:17.730330Z",
          "iopub.execute_input": "2022-03-29T13:06:17.730619Z",
          "iopub.status.idle": "2022-03-29T13:06:17.835035Z",
          "shell.execute_reply.started": "2022-03-29T13:06:17.730560Z",
          "shell.execute_reply": "2022-03-29T13:06:17.833370Z"
        },
        "trusted": true,
        "id": "4dAM3jnUyr52"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame({'id': tweet_id, 'target': predictions})\n",
        "output.to_csv('my_submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-29T13:06:18.557174Z",
          "iopub.execute_input": "2022-03-29T13:06:18.557646Z",
          "iopub.status.idle": "2022-03-29T13:06:18.570843Z",
          "shell.execute_reply.started": "2022-03-29T13:06:18.557423Z",
          "shell.execute_reply": "2022-03-29T13:06:18.569582Z"
        },
        "trusted": true,
        "id": "LUIL2FZ3yr53"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "ZdtTOtDoyr53"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}